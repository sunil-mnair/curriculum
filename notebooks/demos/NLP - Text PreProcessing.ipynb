{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f43fb67-c528-4e97-9b1d-e5eb77394cfe",
   "metadata": {},
   "source": [
    "# NLP - Text Pre-Processing\n",
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27b93e01-befc-4443-8a27-0a8341cebd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunilnair/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download necessary NLTK packages\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26db006b-74cc-4b2f-ac5f-550243a73c8a",
   "metadata": {},
   "source": [
    "## Sample text for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae2fa64f-0e15-42b3-836e-bcc92187c4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"\"\"In the summer of 2024, Dr. Emily Rivera and her team at the University of California, Berkeley, \n",
    "embarked on a project: to develop an AI capable of understanding complex legal documents. \n",
    "Despite the challenges—differing formats, ambiguous language, and nuanced legal jargon—they achieved remarkable success. \n",
    "By September, their prototype had parsed over 1,000 documents, correctly identifying key legal terms with 98.5% accuracy. \n",
    "What's next for Dr. Rivera's team? 'The sky's the limit,' she says.\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c7d168-7c90-4629-8fc6-2116b975f335",
   "metadata": {},
   "source": [
    "## Functions for Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79bde44c-5038-4594-a413-c1d42e42092d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Noise Removal\n",
    "def remove_noise(text):\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'\\s+\\W|\\W+\\s|\\W+', ' ', text)  # Remove punctuations and special characters\n",
    "    return text.strip()\n",
    "\n",
    "# 2. Tokenization\n",
    "def tokenize_text(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "# 3. Text Normalization (lowercasing)\n",
    "def normalize_text(tokens):\n",
    "    return [token.lower() for token in tokens]\n",
    "\n",
    "# 4. Lemmatization\n",
    "def lemmatize_tokens(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "# 5. Stopword Removal\n",
    "def remove_stopwords(tokens):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return [token for token in tokens if token not in stop_words]\n",
    "\n",
    "# 6. Part-of-Speech Tagging\n",
    "def pos_tagging(tokens):\n",
    "    return pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a5b3d2-9e48-4c5f-be95-a47668c617dc",
   "metadata": {},
   "source": [
    "## Text Pre-processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c413e8ce-635a-44a8-921f-9c75da080ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Step-by-step pre-processing\n",
    "    text_without_noise = remove_noise(text)\n",
    "    tokens = tokenize_text(text_without_noise)\n",
    "    normalized_tokens = normalize_text(tokens)\n",
    "    tokens_without_stopwords = remove_stopwords(normalized_tokens)\n",
    "    lemmatized_tokens = lemmatize_tokens(tokens_without_stopwords)\n",
    "    pos_tags = pos_tagging(lemmatized_tokens)\n",
    "\n",
    "    # Display the results\n",
    "    print(\"Original Text:\", text)\n",
    "    print(\"\\nText without Noise:\", text_without_noise)\n",
    "    print(\"\\nTokens:\", tokens)\n",
    "    print(\"\\nNormalized Tokens:\", normalized_tokens)\n",
    "    print(\"\\nTokens without Stopwords:\", tokens_without_stopwords)\n",
    "    print(\"\\nLemmatized Tokens:\", lemmatized_tokens)\n",
    "    print(\"\\nPart-of-Speech Tags:\", pos_tags)\n",
    "    \n",
    "    # Generate Token IDs after the entire preprocessing\n",
    "    token_ids = {token: idx for idx, token in enumerate(lemmatized_tokens)}\n",
    "    print(\"\\nToken IDs:\", token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7499f69b-9dad-4060-b065-48be1f252ac6",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f137de8-ec8f-4249-afb6-414938ba7b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: In the summer of 2024, Dr. Emily Rivera and her team at the University of California, Berkeley, \n",
      "embarked on a project: to develop an AI capable of understanding complex legal documents. \n",
      "Despite the challenges—differing formats, ambiguous language, and nuanced legal jargon—they achieved remarkable success. \n",
      "By September, their prototype had parsed over 1,000 documents, correctly identifying key legal terms with 98.5% accuracy. \n",
      "What's next for Dr. Rivera's team? 'The sky's the limit,' she says.\n",
      "\n",
      "Text without Noise: In the summer of  Dr Emily Rivera and her team at the University of California Berkeley embarked on a project to develop an AI capable of understanding complex legal documents Despite the challenges differing formats ambiguous language and nuanced legal jargon they achieved remarkable success By September their prototype had parsed over  documents correctly identifying key legal terms with  accuracy What s next for Dr Rivera s team  The sky s the limit she says\n",
      "\n",
      "Tokens: ['In', 'the', 'summer', 'of', 'Dr', 'Emily', 'Rivera', 'and', 'her', 'team', 'at', 'the', 'University', 'of', 'California', 'Berkeley', 'embarked', 'on', 'a', 'project', 'to', 'develop', 'an', 'AI', 'capable', 'of', 'understanding', 'complex', 'legal', 'documents', 'Despite', 'the', 'challenges', 'differing', 'formats', 'ambiguous', 'language', 'and', 'nuanced', 'legal', 'jargon', 'they', 'achieved', 'remarkable', 'success', 'By', 'September', 'their', 'prototype', 'had', 'parsed', 'over', 'documents', 'correctly', 'identifying', 'key', 'legal', 'terms', 'with', 'accuracy', 'What', 's', 'next', 'for', 'Dr', 'Rivera', 's', 'team', 'The', 'sky', 's', 'the', 'limit', 'she', 'says']\n",
      "\n",
      "Normalized Tokens: ['in', 'the', 'summer', 'of', 'dr', 'emily', 'rivera', 'and', 'her', 'team', 'at', 'the', 'university', 'of', 'california', 'berkeley', 'embarked', 'on', 'a', 'project', 'to', 'develop', 'an', 'ai', 'capable', 'of', 'understanding', 'complex', 'legal', 'documents', 'despite', 'the', 'challenges', 'differing', 'formats', 'ambiguous', 'language', 'and', 'nuanced', 'legal', 'jargon', 'they', 'achieved', 'remarkable', 'success', 'by', 'september', 'their', 'prototype', 'had', 'parsed', 'over', 'documents', 'correctly', 'identifying', 'key', 'legal', 'terms', 'with', 'accuracy', 'what', 's', 'next', 'for', 'dr', 'rivera', 's', 'team', 'the', 'sky', 's', 'the', 'limit', 'she', 'says']\n",
      "\n",
      "Tokens without Stopwords: ['summer', 'dr', 'emily', 'rivera', 'team', 'university', 'california', 'berkeley', 'embarked', 'project', 'develop', 'ai', 'capable', 'understanding', 'complex', 'legal', 'documents', 'despite', 'challenges', 'differing', 'formats', 'ambiguous', 'language', 'nuanced', 'legal', 'jargon', 'achieved', 'remarkable', 'success', 'september', 'prototype', 'parsed', 'documents', 'correctly', 'identifying', 'key', 'legal', 'terms', 'accuracy', 'next', 'dr', 'rivera', 'team', 'sky', 'limit', 'says']\n",
      "\n",
      "Lemmatized Tokens: ['summer', 'dr', 'emily', 'rivera', 'team', 'university', 'california', 'berkeley', 'embarked', 'project', 'develop', 'ai', 'capable', 'understanding', 'complex', 'legal', 'document', 'despite', 'challenge', 'differing', 'format', 'ambiguous', 'language', 'nuanced', 'legal', 'jargon', 'achieved', 'remarkable', 'success', 'september', 'prototype', 'parsed', 'document', 'correctly', 'identifying', 'key', 'legal', 'term', 'accuracy', 'next', 'dr', 'rivera', 'team', 'sky', 'limit', 'say']\n",
      "\n",
      "Part-of-Speech Tags: [('summer', 'NN'), ('dr', 'NNS'), ('emily', 'RB'), ('rivera', 'VBP'), ('team', 'NN'), ('university', 'NN'), ('california', 'NN'), ('berkeley', 'NN'), ('embarked', 'VBD'), ('project', 'NN'), ('develop', 'VB'), ('ai', 'JJ'), ('capable', 'JJ'), ('understanding', 'NN'), ('complex', 'JJ'), ('legal', 'JJ'), ('document', 'NN'), ('despite', 'IN'), ('challenge', 'NN'), ('differing', 'VBG'), ('format', 'RB'), ('ambiguous', 'JJ'), ('language', 'NN'), ('nuanced', 'VBD'), ('legal', 'JJ'), ('jargon', 'NN'), ('achieved', 'VBD'), ('remarkable', 'JJ'), ('success', 'NN'), ('september', 'NN'), ('prototype', 'NN'), ('parsed', 'VBD'), ('document', 'NN'), ('correctly', 'RB'), ('identifying', 'VBG'), ('key', 'JJ'), ('legal', 'JJ'), ('term', 'NN'), ('accuracy', 'NN'), ('next', 'JJ'), ('dr', 'NN'), ('rivera', 'NN'), ('team', 'NN'), ('sky', 'NN'), ('limit', 'NN'), ('say', 'VBP')]\n",
      "\n",
      "Token IDs: {'summer': 0, 'dr': 40, 'emily': 2, 'rivera': 41, 'team': 42, 'university': 5, 'california': 6, 'berkeley': 7, 'embarked': 8, 'project': 9, 'develop': 10, 'ai': 11, 'capable': 12, 'understanding': 13, 'complex': 14, 'legal': 36, 'document': 32, 'despite': 17, 'challenge': 18, 'differing': 19, 'format': 20, 'ambiguous': 21, 'language': 22, 'nuanced': 23, 'jargon': 25, 'achieved': 26, 'remarkable': 27, 'success': 28, 'september': 29, 'prototype': 30, 'parsed': 31, 'correctly': 33, 'identifying': 34, 'key': 35, 'term': 37, 'accuracy': 38, 'next': 39, 'sky': 43, 'limit': 44, 'say': 45}\n"
     ]
    }
   ],
   "source": [
    "# Run the text preprocessing on sample text\n",
    "preprocess_text(sample_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
